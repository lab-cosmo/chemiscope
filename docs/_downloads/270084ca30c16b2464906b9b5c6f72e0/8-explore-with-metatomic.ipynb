{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\n# Using metatomic models for dataset exploration\n\nIn this example, we demonstrate how to create and use a `metatomic`_ model with\n:py:func:`chemiscope.metatomic_featurizer` to extract features from the model, which are\nthen displayed using a chemiscope widget. To use this function, some additional\ndependencies are required. You can install them with the following command:\n\n.. code:: bash\n\n    pip install chemiscope[explore]\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Firstly, we import necessary packages and read structures from the dataset.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from typing import Dict, List, Optional\n\nimport ase.io\n\nimport chemiscope\n\n\nframes = ase.io.read(\"data/explore_c-gap-20u.xyz\", \":\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Using pre-trained models\n\nMost commonly, you will have an already existing model in metatensor format that\nyou'll want to use for dataset exploration. In this case, you'll have to create a\n``featurizer`` function using :py:func:`chemiscope.metatomic_featurizer`.\n\n``metatomic_featurizer`` takes an existing model as input. It can be either a\n``AtomisticModel`` instance or a path to a pre-trained model file (here\n``\"model.pt\"``)\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "featurizer = chemiscope.metatomic_featurizer(model=\"model.pt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "From here, you can use :py:func:`chemiscope.explore` to visualize the features\ncomputed from the structures. For this, we are passing the frames, the ``featurizer``\nfunction, and \u2014 as the model computes per-atom properties \u2014 environments.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "chemiscope.explore(\n    frames=frames,\n    featurize=featurizer,\n    environments=chemiscope.all_atomic_environments(frames),\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Defining a custom model\n\nLet's now move on and see how one can define a fully custom model to use through the\nmetatomic interface.\n\nHere we will use an atom-centered representation, where each atomic environment is\nrepresented with the moments of the positions of the neighbors up to a maximal order.\n\nThe model computes moments up to a specified maximum order $k_{\\text{max}}$,\ncomputing a representation $F_i^k$\n\n\\begin{align}F_i^k = \\sum_{j} \\frac{r_{ij}}{r_c}^k\\end{align}\n\nwhere $r_{ij}$ is the distance between atom $i$ and its neighbor\n$j$, $k$ is the moment order and $r_c$ is the cutoff radius.\n\nHaving computed these moments, the model will take a PCA of their values to\nextract the three most relevant dimensions.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import torch  # noqa: E402\nfrom metatensor.torch import Labels, TensorBlock, TensorMap  # noqa: E402\nfrom metatomic.torch import (  # noqa: E402\n    AtomisticModel,\n    ModelCapabilities,\n    ModelMetadata,\n    ModelOutput,\n    NeighborListOptions,\n    System,\n)\n\n\nclass FeatureModel(torch.nn.Module):\n    def __init__(self, cutoff: float, max_k: int):\n        super().__init__()\n        self.cutoff = cutoff\n        self.max_k = max_k\n\n        self._neighbors_options = NeighborListOptions(\n            cutoff=cutoff, full_list=True, strict=True\n        )\n\n    def requested_neighbor_lists(self) -> List[NeighborListOptions]:\n        # our model requires a neighbor list, that will be computed and provided to it\n        # automatically.\n        return [self._neighbors_options]\n\n    def forward(\n        self,\n        systems: List[System],\n        outputs: Dict[str, ModelOutput],\n        selected_atoms: Optional[Labels] = None,\n    ) -> Dict[str, TensorMap]:\n        if list(outputs.keys()) != [\"features\"]:\n            raise ValueError(\n                \"this model can only compute 'features', but outputs contains other \"\n                f\"keys: {', '.join(outputs.keys())}\"\n            )\n\n        if not outputs[\"features\"].per_atom:\n            raise NotImplementedError(\"per structure features are not implemented\")\n\n        all_features = []\n        all_samples = []\n\n        for system_i, system in enumerate(systems):\n            dtype = system.positions.dtype\n            device = system.positions.device\n            n_atoms = len(system.positions)\n\n            # Initialize a tensor to store features for each atom\n            features = torch.zeros((n_atoms, self.max_k), dtype=dtype, device=device)\n\n            # get the neighbor list for this system\n            neighbors = system.get_neighbor_list(self._neighbors_options)\n            i = neighbors.samples.column(\"first_atom\")\n\n            r_ij = torch.linalg.vector_norm(neighbors.values.reshape(-1, 3), dim=1)\n            r_ij /= self.cutoff\n\n            for k in range(self.max_k):\n                features[i, k] += torch.pow(r_ij, k)\n\n            all_features.append(features)\n\n            # Create labels for each atom in the system\n            system_atom_labels = torch.tensor(\n                [[system_i, atom_i] for atom_i in range(n_atoms)]\n            )\n            all_samples.append(system_atom_labels)\n\n        # Concatenate features and labels across all systems\n        features_tensor = torch.cat(all_features, dim=0)\n        samples_tensor = torch.cat(all_samples, dim=0)\n\n        # Take the PCA of the features\n        _, _, V = torch.linalg.svd(features_tensor - features_tensor.mean())\n        features_pca = features_tensor @ V[:3].T\n\n        # Add metadata to the output\n        block = TensorBlock(\n            values=features_pca,\n            samples=Labels(names=[\"system\", \"atom\"], values=samples_tensor),\n            components=[],\n            properties=Labels(\n                names=[\"feature\"],\n                values=torch.tensor([[0], [1], [2]]),\n            ),\n        )\n        return {\n            \"features\": TensorMap(\n                keys=Labels(names=[\"_\"], values=torch.tensor([[0]])), blocks=[block]\n            )\n        }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "With the class defined, we can now create an instance of the model, giving ``cutoff``\nand ``max_k`` as a maximal moment to compute. We don\u2019t need to train this model since\nthere are no trainable parameters inside.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model = FeatureModel(cutoff=4.5, max_k=6)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, we set up the model metadata and capabilities:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "metadata = ModelMetadata(\n    name=\"Example moment model\",\n    description=(\n        \"A model that computes atom-centered features based on the distances of \"\n        \"neighboring atoms\"\n    ),\n)\n\ncapabilities = ModelCapabilities(\n    outputs={\n        \"features\": ModelOutput(per_atom=True),\n    },\n    atomic_types=[6],\n    length_unit=\"angstrom\",\n    interaction_range=0.0,\n    supported_devices=[\"cpu\"],\n    dtype=\"float64\",\n)\n\nmta_model = AtomisticModel(model.eval(), metadata, capabilities)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For a more detailed example of exporting a model, please check the related\n[tutorial](https://docs.metatensor.org/metatomic/latest/examples/1-export-atomistic-model.html)\nin metatomic documentation.\n\nOnce the model is fully defined, we can use it with\n:py:func:`chemiscope.metatomic_featurizer`:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "featurizer = chemiscope.metatomic_featurizer(mta_model, check_consistency=True)\nchemiscope.explore(\n    frames=frames,\n    featurize=featurizer,\n    environments=chemiscope.all_atomic_environments(frames),\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The metatomic model can also be easily exported, to be shared with collaborators for\nuse in their visualization workflows\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "mta_model.save(\"model-exported.pt\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}